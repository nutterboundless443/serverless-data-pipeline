service: serverless-data-pipeline

provider:
  name: aws
  runtime: python3.8
  stage: dev
  region: us-east-1

functions:
  dataProcessor:
    handler: src/handler.process_data
    events:
      - http:
          path: upload
          method: post

resources:
  Resources:
    # S3 Bucket to store data files
    DataBucket:
      Type: 'AWS::S3::Bucket'
      Properties:
        BucketName: my-serverless-data-pipeline-bucket
    # DynamoDB table to store processed data
    DataTable:
      Type: 'AWS::DynamoDB::Table'
      Properties:
        TableName: DataTable
        AttributeDefinitions:
          # Define the primary key 'id' of type String
          - AttributeName: id
            AttributeType: S
        KeySchema:
          # Specify 'id' as the HASH key
          - AttributeName: id
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1